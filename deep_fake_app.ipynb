{"cells":[{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21537,"status":"ok","timestamp":1757409827026,"user":{"displayName":"DeepFake","userId":"16151547872457837978"},"user_tz":-330},"id":"ikhvbX02sBwK","outputId":"53f67598-e939-4f5d-e31d-158736a6e106"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n","Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask) (1.9.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask) (8.2.1)\n","Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask) (2.2.0)\n","Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask) (3.1.6)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask) (3.0.2)\n","Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask) (3.1.3)\n","Requirement already satisfied: flask_ngrok in /usr/local/lib/python3.12/dist-packages (0.0.25)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.12/dist-packages (from flask_ngrok) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from flask_ngrok) (2.32.4)\n","Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask_ngrok) (1.9.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask_ngrok) (8.2.1)\n","Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask_ngrok) (2.2.0)\n","Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask_ngrok) (3.1.6)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask_ngrok) (3.0.2)\n","Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask_ngrok) (3.1.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->flask_ngrok) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->flask_ngrok) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->flask_ngrok) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->flask_ngrok) (2025.8.3)\n","Requirement already satisfied: face_recognition in /usr/local/lib/python3.12/dist-packages (1.3.0)\n","Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from face_recognition) (0.3.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.12/dist-packages (from face_recognition) (8.2.1)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.12/dist-packages (from face_recognition) (19.24.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from face_recognition) (2.0.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from face_recognition) (11.3.0)\n","Requirement already satisfied: pyngrok==7.1.2 in /usr/local/lib/python3.12/dist-packages (7.1.2)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok==7.1.2) (6.0.2)\n","Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}],"source":["!pip install Flask\n","!pip install flask_ngrok\n","!pip install face_recognition\n","!pip install pyngrok==7.1.2\n","!ngrok authtoken 2fIxJpLgjs653mjOWz1NVxPGrN9_39Kd7f2WXEsfdX8K2fNnP"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":19330,"status":"ok","timestamp":1757409188322,"user":{"displayName":"DeepFake","userId":"16151547872457837978"},"user_tz":-330},"id":"OlChuLZit955"},"outputs":[],"source":["from flask_ngrok import run_with_ngrok\n","from flask import Flask\n","from pyngrok import ngrok\n","import torch\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","import os\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","from torch.autograd import Variable\n","import time\n","import sys\n","from torch import nn\n","from torchvision import models\n","import face_recognition"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":371,"status":"ok","timestamp":1757409192644,"user":{"displayName":"DeepFake","userId":"16151547872457837978"},"user_tz":-330},"id":"wDrkjG4QKRHB"},"outputs":[],"source":["im_size = 112\n","mean=[0.485, 0.456, 0.406]\n","std=[0.229, 0.224, 0.225]\n","sm = nn.Softmax()\n","inv_normalize =  transforms.Normalize(mean=-1*np.divide(mean,std),std=np.divide([1,1,1],std))\n","train_transforms = transforms.Compose([\n","                                        transforms.ToPILImage(),\n","                                        transforms.Resize((im_size,im_size)),\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize(mean,std)])\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":605,"status":"ok","timestamp":1757409197203,"user":{"displayName":"DeepFake","userId":"16151547872457837978"},"user_tz":-330},"id":"ADKuAVwUvi_7"},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, num_classes,latent_dim= 2048, lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n","        super(Model, self).__init__()\n","        model = models.resnext50_32x4d(pretrained = True)\n","        self.model = nn.Sequential(*list(model.children())[:-2])\n","        self.lstm = nn.LSTM(latent_dim,hidden_dim, lstm_layers,  bidirectional)\n","        self.relu = nn.LeakyReLU()\n","        self.dp = nn.Dropout(0.4)\n","        self.linear1 = nn.Linear(2048,num_classes)\n","        self.avgpool = nn.AdaptiveAvgPool2d(1)\n","    def forward(self, x):\n","        batch_size,seq_length, c, h, w = x.shape\n","        x = x.view(batch_size * seq_length, c, h, w)\n","        fmap = self.model(x)\n","        x = self.avgpool(fmap)\n","        x = x.view(batch_size,seq_length,2048)\n","        x_lstm,_ = self.lstm(x,None)\n","        return fmap,self.dp(self.linear1(x_lstm[:,-1,:]))"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":393,"status":"ok","timestamp":1757409200124,"user":{"displayName":"DeepFake","userId":"16151547872457837978"},"user_tz":-330},"id":"8mePUns0t_Sm"},"outputs":[],"source":["class validation_dataset(Dataset):\n","    def __init__(self,video_names,sequence_length = 60,transform = None):\n","        self.video_names = video_names\n","        self.transform = transform\n","        self.count = sequence_length\n","    def __len__(self):\n","        return len(self.video_names)\n","    def __getitem__(self,idx):\n","        video_path = self.video_names[idx]\n","        frames = []\n","        a = int(100/self.count)\n","        first_frame = np.random.randint(0,a)\n","        for i,frame in enumerate(self.frame_extract(video_path)):\n","            #if(i % a == first_frame):\n","            faces = face_recognition.face_locations(frame)\n","            try:\n","              top,right,bottom,left = faces[0]\n","              frame = frame[top:bottom,left:right,:]\n","            except:\n","              pass\n","            frames.append(self.transform(frame))\n","            if(len(frames) == self.count):\n","              break\n","        #print(\"no of frames\",len(frames))\n","        frames = torch.stack(frames)\n","        frames = frames[:self.count]\n","        return frames.unsqueeze(0)\n","    def frame_extract(self,path):\n","      vidObj = cv2.VideoCapture(path)\n","      success = 1\n","      while success:\n","          success, image = vidObj.read()\n","          if success:\n","              yield image\n","def im_convert(tensor):\n","    \"\"\" Display a tensor as an image. \"\"\"\n","    image = tensor.to(\"cpu\").clone().detach()\n","    image = image.squeeze()\n","    image = inv_normalize(image)\n","    image = image.numpy()\n","    image = image.transpose(1,2,0)\n","    image = image.clip(0, 1)\n","    cv2.imwrite('./2.png',image*255)\n","    return image\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":370,"status":"ok","timestamp":1757409205556,"user":{"displayName":"DeepFake","userId":"16151547872457837978"},"user_tz":-330},"id":"YnnsEHXHuDzO"},"outputs":[],"source":["def im_plot(tensor):\n","    image = tensor.cpu().numpy().transpose(1,2,0)\n","    b,g,r = cv2.split(image)\n","    image = cv2.merge((r,g,b))\n","    image = image*[0.22803, 0.22145, 0.216989] +  [0.43216, 0.394666, 0.37645]\n","    image = image*255.0\n","    plt.imshow(image.astype(int))\n","    plt.show()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":380,"status":"ok","timestamp":1757409210282,"user":{"displayName":"DeepFake","userId":"16151547872457837978"},"user_tz":-330},"id":"XkRghC8wvpVw"},"outputs":[],"source":["\n","def predict(model,img,path = './'):\n","  fmap,logits = model(img.to('cuda'))\n","  params = list(model.parameters())\n","  weight_softmax = model.linear1.weight.detach().cpu().numpy()\n","  logits = sm(logits)\n","  _,prediction = torch.max(logits,1)\n","  confidence = logits[:,int(prediction.item())].item()*100\n","  print('confidence of prediction:',logits[:,int(prediction.item())].item()*100)\n","  idx = np.argmax(logits.detach().cpu().numpy())\n","  bz, nc, h, w = fmap.shape\n","  out = np.dot(fmap[-1].detach().cpu().numpy().reshape((nc, h*w)).T,weight_softmax[idx,:].T)\n","  predict = out.reshape(h,w)\n","  predict = predict - np.min(predict)\n","  predict_img = predict / np.max(predict)\n","  predict_img = np.uint8(255*predict_img)\n","  out = cv2.resize(predict_img, (im_size,im_size))\n","  heatmap = cv2.applyColorMap(out, cv2.COLORMAP_JET)\n","  img = im_convert(img[:,-1,:,:,:])\n","  result = heatmap * 0.5 + img*0.8*255\n","  cv2.imwrite('/content/1.png',result)\n","  result1 = heatmap * 0.5/255 + img*0.8\n","  r,g,b = cv2.split(result1)\n","  result1 = cv2.merge((r,g,b))\n","  plt.imshow(result1)\n","  plt.show()\n","  return [int(prediction.item()),confidence]"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1757409213146,"user":{"displayName":"DeepFake","userId":"16151547872457837978"},"user_tz":-330},"id":"Os1A4UuOuEns"},"outputs":[],"source":["def prediction_result(video_path):\n","  im_size = 112\n","  mean=[0.485, 0.456, 0.406]\n","  std=[0.229, 0.224, 0.225]\n","\n","  train_transforms = transforms.Compose([\n","                                          transforms.ToPILImage(),\n","                                          transforms.Resize((im_size,im_size)),\n","                                          transforms.ToTensor(),\n","                                          transforms.Normalize(mean,std)])\n","\n","\n","  path_to_videos= [video_path]\n","  flag = True\n","  video_dataset = validation_dataset(path_to_videos,sequence_length = 20,transform = train_transforms)\n","\n","  model = Model(2).cuda()\n","  # path_to_model = '/content/drive/MyDrive/weights/model_90_acc_20_frames_FF_data.pt'\n","  path_to_model = '/content/drive/MyDrive/weights/checkpoint.pt'\n","  model.load_state_dict(torch.load(path_to_model))\n","  model.eval()\n","  for i in range(0,len(path_to_videos)):\n","    print(path_to_videos[i])\n","    prediction = predict(model,video_dataset[i],'./')\n","    if prediction[0] == 1:\n","      print(\"REAL\")\n","      return \"REAL\"\n","    else:\n","      print(\"FAKE\")\n","      return \"FAKE\""]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1119,"status":"ok","timestamp":1757409217384,"user":{"displayName":"DeepFake","userId":"16151547872457837978"},"user_tz":-330},"id":"UJ-a_cWca_2W","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6470f16-c9a3-41ab-8bf2-06e638b5897e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n","  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n","/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n","  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n","/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n","  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n","/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n","  match = re.search('\\d+$', rotation_line)\n","WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n","  if event.key is 'enter':\n","\n"]}],"source":["from moviepy.editor import VideoFileClip\n","\n","def convert_to_gif(input_file, output_file):\n","    clip = VideoFileClip(input_file)\n","    clip.write_gif(output_file)\n","\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":386,"status":"ok","timestamp":1757409223701,"user":{"displayName":"DeepFake","userId":"16151547872457837978"},"user_tz":-330},"id":"o0jCDN7kbNYj"},"outputs":[],"source":["import cv2\n","import face_recognition\n","from google.colab.patches import cv2_imshow\n","\n","def process_video(input_video_path, output_video_path, flag, duration_sec=4):\n","\n","    cap = cv2.VideoCapture(input_video_path)\n","\n","\n","    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    frames_to_process = min(int(fps * duration_sec), total_frames)\n","\n","\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","\n","\n","    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n","\n","    label = \"fake\" if flag else \"real\"\n","\n","    frame_count = 0\n","    while frame_count < frames_to_process:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","\n","        rgb_frame = frame[:, :, ::-1]\n","\n","\n","        face_locations = face_recognition.face_locations(rgb_frame)\n","\n","\n","        for (top, right, bottom, left) in face_locations:\n","            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n","            cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n","\n","\n","        out.write(frame)\n","\n","\n","        cv2_imshow(frame)\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","\n","        frame_count += 1\n","\n","    # Release resources\n","    cap.release()\n","    out.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":609,"status":"ok","timestamp":1757409891605,"user":{"displayName":"DeepFake","userId":"16151547872457837978"},"user_tz":-330},"id":"8RxwR7rSwb9W","outputId":"abf57773-f185-48e8-93bb-cdf2152f8c34"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'https://4e232623dfef.ngrok-free.app'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}],"source":["# ngrok.set_auth_token(\"2fIxJpLgjs653mjOWz1NVxPGrN9_39Kd7f2WXEsfdX8K2fNnP\")\n","port=5000\n","ngrok.connect(port).public_url"]},{"cell_type":"markdown","metadata":{"id":"rtxi8LXcWyjT"},"source":["Ignore this"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":3749,"status":"ok","timestamp":1757409590393,"user":{"displayName":"DeepFake","userId":"16151547872457837978"},"user_tz":-330},"id":"SCNw3uptgabr","outputId":"dd576287-b535-4a8a-f033-4c89e2b9843e"},"outputs":[{"output_type":"stream","name":"stdout","text":["https://5nspy7wsti-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n"]}],"source":["# @title Default title text\n","from google.colab.output import eval_js\n","print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3A861jxluSyO","outputId":"ceb58535-e519-4b6f-cd2f-e8c368f05f11","executionInfo":{"status":"ok","timestamp":1757409930247,"user_tz":-330,"elapsed":34448,"user":{"displayName":"DeepFake","userId":"16151547872457837978"}}},"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","ERROR:__main__:Exception on / [GET]\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/flask/app.py\", line 1511, in wsgi_app\n","    response = self.full_dispatch_request()\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/flask/app.py\", line 920, in full_dispatch_request\n","    return self.finalize_request(rv)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/flask/app.py\", line 939, in finalize_request\n","    response = self.make_response(rv)\n","               ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/flask/app.py\", line 1249, in make_response\n","    raise TypeError(\n","TypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a TemplateNotFound.\n","INFO:werkzeug:127.0.0.1 - - [09/Sep/2025 09:25:11] \"\u001b[35m\u001b[1mGET / HTTP/1.1\u001b[0m\" 500 -\n","INFO:werkzeug:127.0.0.1 - - [09/Sep/2025 09:25:11] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"]}],"source":["from flask import Flask ,  render_template , redirect, request, jsonify, send_from_directory , url_for\n","template_folder='/content/drive/MyDrive/template'\n","static_folder='/content/drive/MyDrive/static'\n","app = Flask(__name__,template_folder=template_folder,static_folder=static_folder)\n","\n","\n","@app.route(\"/\" , methods=[\"GET\"])\n","def home():\n","\ttry:\n","\t\treturn render_template(\"home.html\")\n","\texcept Exception as e:\n","\t\treturn e\n","\n","@app.route(\"/upload\" , methods=[\"POST\"])\n","def HandleUpload():\n","\ttry:\n","\n","\t\tf = request.files[\"video\"]\n","\t\t# first create static/videos then try to upload\n","\t\tvideoName = f\"/content/drive/MyDrive/static/videos/{f.filename}\"\n","\t\tprint(f)\n","\t\tf.save(videoName)\n","\t\tprint(\"File saved!!!\")\n","\t\t# videoName=create_preprocessed_face_videos(videoName)\n","\n","\t\t# result_of_prediction=prediction_result(videoName)\n","\n","\t\treturn redirect(f\"/result-page/{f.filename}\")\n","\t\t# return redirect(f\"/result/{True}\")\n","\texcept Exception as e:\n","\t\tprint(e)\n","\t\treturn e\n","\n","@app.route(\"/result-page/<string:fileName>\" , methods=[\"GET\"])\n","def Loader(fileName):\n","\ttry:\n","\t\tprint(fileName)\n","\t\treturn render_template(\"Result.html\", path=f\"videos/{fileName}\", fileName=fileName, isLoading=True)\n","\texcept Exception as e:\n","\t\treturn e\n","\n","@app.route(\"/predict\" , methods=[\"GET\"])\n","def restric():\n","\treturn redirect(url_for(\"home\"))\n","\n","@app.route(\"/predict/<string:fileName>\" , methods=[\"GET\"])\n","def Predict(fileName):\n","\ttry:\n","\t\tprint(fileName)\n","\t\tvideoName = f\"/content/drive/MyDrive/static/videos/{fileName}\"\n","\t\tresult_of_prediction=prediction_result(videoName)\n","\t\tprint(result_of_prediction)\n","\t\tprint(\"prediction completed\")\n","\n","\t\tvideo_path = '/content/drive/MyDrive/static/videos/'\n","\t\tinput_video_path = os.path.join(video_path, fileName)\n","\t\toutput_video_path = os.path.join(video_path, 'output.mp4')\n","\t\tflag = False if result_of_prediction == \"REAL\" else True\n","\t\tprocess_video(input_video_path, output_video_path, flag, duration_sec=4)\n","\t\tinput_video = output_video_path\n","\t\toutput_gif = os.path.join(video_path, 'output.gif')\n","\t\tconvert_to_gif(input_video, output_gif)\n","\n","\t\treturn jsonify({'result' : result_of_prediction == 'REAL', 'isLoading':False , 'fileName':\"videos/output.gif\"})\n","\texcept Exception as e:\n","\t\treturn e\n","# unused route\n","@app.route(\"/temp\")\n","def temporary():\n","\ttry:\n","\t\treturn render_template(\"temp.html\")\n","\texcept Exception as e:\n","\t\treturn e\n","# to be used route\n","@app.route(\"/result-vid/<string:result>\" , methods=[\"GET\"])\n","def Result(result,file):\n","\tprint(\"result page\")\n","\tprint(result)\n","\tif file:\n","\t\tvideo_path = '/content/drive/MyDrive/static/videos/'\n","\t\tfile.save(os.path.join(video_path, file.filename))\n","\t\tinput_video_path = os.path.join(video_path, file.filename)\n","\t\toutp=\"output_video.mp4\"\n","\t\toutput_video_path = os.path.join(video_path, 'output.mp4')\n","\t\tif result == \"REAL\":\n","\t\t\tflag = False  # Set to False for \"real\"\n","\t\telse:\n","\t\t\tflag = True  # Set to True for \"fake\"\n","\n","\t\tprocess_video(input_video_path, output_video_path, flag, duration_sec=4)\n","\t\tprint('success')\n","    # Redirect to the view page with the filename as a query parameter\n","\t\tinput_video = \"/content/output.mp4\"\n","\t\toutput_gif = \"/content/output.gif\"\n","\t\tconvert_to_gif(input_video, output_gif)\n","\t\treturn redirect(url_for('view_video', filename='output.mp4'))\n","\n","\treturn result\n","\n","\n","\n","\n","if __name__==\"__main__\":\n","  app.run(port=port)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Loj0zhckLr4M"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1S3uPYbbrZRKW_jtvZUavC_UJDqmV6MVc","authorship_tag":"ABX9TyOFeJ/jl6MmwPSxs8MdNJ5L"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}